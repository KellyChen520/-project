{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8KJKeC-ASWro",
    "outputId": "650b39ca-2adc-40ae-c00f-7f5726bb2e89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YzEXOv7nhk4"
   },
   "source": [
    "# using colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "T6bY1Xg55HqK"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "import copy\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wozNR86TSZ5n"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kQFikf2o6EF1",
    "outputId": "65b6c57f-188d-44e2-ec19-0e9eac0e6115"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print('device: %s' %device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "XJ-7Yxlc5FlV"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/MyDrive/imb.pickle','rb') as handle:\n",
    "    imb = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "NEP9jZdk5JkT"
   },
   "outputs": [],
   "source": [
    "# exploring data \n",
    "# 0~6 interval. -> standardize\n",
    "std_x_subtrain = copy.deepcopy(imb['X_subtrain'])\n",
    "std_x_valid = copy.deepcopy(imb['X_valid'])\n",
    "std_x_test = copy.deepcopy(imb['X_test'])\n",
    "for i in range(7):\n",
    "    tmpstd = np.std(std_x_subtrain[:,i],ddof=1) # unbiased estimator\n",
    "    tmpmean = np.mean(std_x_subtrain[:,i])\n",
    "    std_x_subtrain[:,i] = (std_x_subtrain[:,i]-tmpmean)/tmpstd\n",
    "for i in range(7):\n",
    "    tmpstd = np.std(std_x_valid[:,i],ddof=1) # unbiased estimator\n",
    "    tmpmean = np.mean(std_x_valid[:,i])\n",
    "    std_x_valid[:,i] = (std_x_valid[:,i]-tmpmean)/tmpstd\n",
    "for i in range(7):\n",
    "    tmpstd = np.std(std_x_test[:,i],ddof=1) # unbiased estimator\n",
    "    tmpmean = np.mean(std_x_test[:,i])\n",
    "    std_x_test[:,i] = (std_x_test[:,i]-tmpmean)/tmpstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "yi5m_RIF6BSP"
   },
   "outputs": [],
   "source": [
    "\n",
    "X_subtrain_tensor = torch.tensor(std_x_subtrain, dtype=torch.float).to(device)\n",
    "y_subtrain_tensor = torch.tensor(imb[\"y_subtrain\"], dtype=torch.float).to(device)\n",
    "X_valid_tensor = torch.tensor(std_x_valid, dtype=torch.float).to(device)\n",
    "y_valid_tensor = torch.tensor(imb[\"y_valid\"], dtype=torch.float).to(device)\n",
    "X_test_tensor = torch.tensor(std_x_test, dtype=torch.float).to(device)\n",
    "y_test_tensor = torch.tensor(imb[\"y_test\"], dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PkwZgfeHCzEY",
    "outputId": "f384bd3b-dcbe-426e-8e16-3907650c62f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "5G6D3ZCRo4tV"
   },
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, Xnp, Ynp):\n",
    "        'Initialization, passing Xnp and Ynp'\n",
    "        self.labels = Ynp\n",
    "        self.nobs = Xnp.shape[0]        \n",
    "        self.Xnp = Xnp\n",
    "        self.Ynp = Ynp\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return self.nobs\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'        \n",
    "        X = self.Xnp[index]\n",
    "        y = self.Ynp[index]\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q5enu48mnlNh"
   },
   "source": [
    "# DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "TTh3_aBjpHSN"
   },
   "outputs": [],
   "source": [
    "class DNN(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out, nb_h_layers, dropout = 0):\n",
    "        super(DNN, self).__init__() \n",
    "        nn_list = []\n",
    "        # hidden layer\n",
    "        for i in range(nb_h_layers):\n",
    "            if i == 0:\n",
    "                nn_list.append(torch.nn.Linear(D_in, H))\n",
    "            else:\n",
    "                nn_list.append(torch.nn.Linear(H, H))\n",
    "        # output layer\n",
    "        nn_list.append(torch.nn.Linear(H, D_out))\n",
    "        \n",
    "        self.nb_layers = nb_h_layers + 1\n",
    "        self.layer_list = torch.nn.ModuleList(nn_list)\n",
    "        self.dropout = torch.nn.Dropout(dropout, inplace = True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # hidden layer\n",
    "        for i in range(self.nb_layers - 1):\n",
    "            x = F.relu(self.layer_list[i](x))\n",
    "            self.dropout(x)\n",
    "        # output layer\n",
    "        x = self.layer_list[self.nb_layers - 1](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fuIpeJIWnnbF"
   },
   "source": [
    "# Focal Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "w3xXerKspnVB"
   },
   "outputs": [],
   "source": [
    "# loss focal loss\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2,reduction=\"mean\",devices=\"cuda\"):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.weight = torch.Tensor([alpha, 1-alpha]).to(devices)\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "    def forward(self, inputs, targets):\n",
    "        log_prob = F.log_softmax(inputs, dim=-1)\n",
    "        prob = torch.exp(log_prob)\n",
    "        return F.nll_loss(\n",
    "            ((1 - prob) ** self.gamma) * log_prob, \n",
    "            targets, \n",
    "            weight=self.weight,\n",
    "            reduction = self.reduction\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "qI3MznvuBgb1"
   },
   "outputs": [],
   "source": [
    "subtrain_set = Dataset(X_subtrain_tensor,y_subtrain_tensor)\n",
    "subtrainloader = data.DataLoader(subtrain_set,batch_size =10000,shuffle=True,num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fUm1Gon2uKn0"
   },
   "outputs": [],
   "source": [
    "lr_rates = [1e-4,1e-3,1e-2,1e-1]\n",
    "dropout_rates = [0.5] \n",
    "Hs = [90, 180, 360] \n",
    "nb_h_layers = [1,2,3,4]\n",
    "alphas = [0.1,0.25,0.4] \n",
    "gammas = [2,3.5,5,7] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ygB_u5OUeyqm"
   },
   "outputs": [],
   "source": [
    "def predicts(ou):\n",
    "    return (ou[:, 0] < ou[:, 1]).type(torch.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "keURQsuQmLES"
   },
   "source": [
    "## In reality, each members in our group is reponsible for a specific learning rate, since it will take too long to finish total 288 models in a computer. Colab session will stop before we can process all models.\n",
    "## This cell is runnable, but i interrupt it . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "R_rqdGsnuJXg",
    "outputId": "28407cc7-8e28-4880-9678-3ba94fc8792f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 2, step = 50, subtrain Focal loss = 5785.666504, valid Focal loss = 1933.515381, f1 = 0.162122, batch_wait = 0\n",
      "Epoch = 4, step = 100, subtrain Focal loss = 5703.922363, valid Focal loss = 1907.503906, f1 = 0.187539, batch_wait = 0\n",
      "Epoch = 7, step = 150, subtrain Focal loss = 5649.405762, valid Focal loss = 1890.755493, f1 = 0.210369, batch_wait = 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-f3cb97eb39ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                             \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.reshape(-1, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "result_pd = pd.DataFrame()\n",
    "\n",
    "# constant\n",
    "max_epoch = 500\n",
    "log_interval = 50\n",
    "max_bacth_wait = 50\n",
    "\n",
    "# tuning parameters\n",
    "\n",
    "for H in Hs:\n",
    "    for nb_h_layer in nb_h_layers:\n",
    "        for a in alphas:\n",
    "            for g in gammas:\n",
    "                for lr_rate in lr_rates:\n",
    "                    \n",
    "                        \n",
    "                    # variables\n",
    "                    step_index = 0\n",
    "                    batch_wait = 0\n",
    "                    subtrain_FLs = []\n",
    "                    valid_FLs = []\n",
    "                    best_valid_FL = -1\n",
    "                    best_state_dict = -1\n",
    "                    # model optimizer loss\n",
    "                    net = DNN(X_subtrain_tensor.shape[1], H, 2, nb_h_layer, dropout = 0.5).to(device)\n",
    "                    optimizer = torch.optim.Adam(net.parameters(), lr = lr_rate)\n",
    "                    loss_fn = FocalLoss(reduction=\"sum\",alpha = a,gamma = g)     # focal loss\n",
    "                    \n",
    "                    for epoch in range(max_epoch):\n",
    "                        for batch_index, (inputs, targets) in enumerate(subtrainloader):\n",
    "                            inputs = inputs.to(device)\n",
    "                            targets = targets.to(device)#.reshape(-1, 1)\n",
    "                            step_index += 1\n",
    "                            net.train()\n",
    "                            optimizer.zero_grad()\n",
    "                            outputs = net(inputs)\n",
    "\n",
    "                            loss = loss_fn(outputs, targets.long())\n",
    "                            #print(loss)\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                            \n",
    "                            if step_index % log_interval == 0:\n",
    "                                net.eval()\n",
    "                                with torch.no_grad():\n",
    "                                    outputs = net(X_subtrain_tensor)\n",
    "                                    subtrain_FL = loss_fn(outputs, y_subtrain_tensor.long())\n",
    "\n",
    "                                    # validation loss\n",
    "                                    outputs = net(X_valid_tensor)\n",
    "                                    op = predicts(outputs)\n",
    "                                    y_valid = imb[\"y_valid\"]\n",
    "                                    f1 = f1_score(y_valid, op.cpu())\n",
    "                                    valid_FL = loss_fn(outputs, y_valid_tensor.long())\n",
    "                                    if valid_FL < best_valid_FL or best_valid_FL  == -1:\n",
    "                                        best_valid_FL = valid_FL\n",
    "                                        best_state_dict = net.state_dict().copy()\n",
    "                                        batch_wait = 0\n",
    "                                    else:\n",
    "                                        batch_wait += 1\n",
    "                                    \n",
    "                                    subtrain_FLs.append(subtrain_FL)\n",
    "                                    valid_FLs.append(valid_FL)\n",
    "                                    print('Epoch = %d, step = %d, subtrain Focal loss = %f, valid Focal loss = %f, f1 = %f, batch_wait = %d'\n",
    "                                          %(epoch, step_index, subtrain_FL, valid_FL, f1, batch_wait))\n",
    "                            if batch_wait == max_bacth_wait:\n",
    "                                break\n",
    "                        if batch_wait == max_bacth_wait:\n",
    "                            break\n",
    "                    result_series = pd.Series({'lr_rate':lr_rate, 'H':H, 'dropout_rate': 0.5, 'nb_h_layers': nb_h_layer, \n",
    "                                            'best_valid_FL': best_valid_FL.item()})\n",
    "                    result_pd = result_pd.append(result_series, ignore_index=True)\n",
    "                    print('lr%f_H%d_a%0.1f_g%0.1f_hl%d best_valid FL: %f'%(lr_rate, H,a,g, nb_h_layer, best_valid_FL.item()))\n",
    "                    net.load_state_dict(best_state_dict)\n",
    "                    torch.save(net, '/content/drive/MyDrive/DNNModels/lr%f_H%d_d%0.1f_hl%d_a%0.2f_g%0.2f'%(lr_rate, H, 0.5, nb_h_layer, a, g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M3Yxb3XqQmt7"
   },
   "outputs": [],
   "source": [
    "# best model\n",
    "dmodel = torch.load('/content/drive/MyDrive/DNNModels/lr0.000100_H180_d0.5_hl3_a0.10_g3.50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4gPwaN24PYYb"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def specificity_score(y_true, y_predict):\n",
    "    conf = confusion_matrix(y_true=y_true, y_pred=y_predict)\n",
    "    return conf[0,0]/(conf[0,0]+conf[0, 1])\n",
    "\n",
    "def opt_score(y_true, y_predict):\n",
    "    target1_pro = 0.919271\n",
    "    target0_pro = 1 - target1_pro\n",
    "    \n",
    "    opt_score = specificity_score(y_true, y_predict)*target1_pro*0.03 - (1-recall_score(y_true, y_predict))*target0_pro\n",
    "    return (opt_score+0.1)*5\n",
    "def opt_score2(y_true, y_predict, x_train):\n",
    "    import numpy as np\n",
    "    pos_index = (y_predict > 0.5).nonzero()\n",
    "    neg_index = (y_predict < 0.5).nonzero()\n",
    "    true_index = (y_true == 1).nonzero()\n",
    "    false_index = (y_true == 0).nonzero()\n",
    "    \n",
    "    # specificity \n",
    "    s_index = np.intersect1d(neg_index, false_index)\n",
    "    s_loss = x_train[s_index,3].sum() # annuty\n",
    "    # (1-recall)\n",
    "    invr_index = np.intersect1d(neg_index, true_index)\n",
    "    invr_loss = x_train[invr_index, 2].sum() # credict\n",
    "    \n",
    "    return (s_loss - invr_loss)/x_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327
    },
    "id": "BOEwY9yNgacT",
    "outputId": "b4f6624c-b30f-4982-96e8-b27af7873cbc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.7170590530697191\n",
      "f1_score = 0.26193909576724067\n",
      "precision = 0.16520436550395892\n",
      "recall = 0.6320098239869013\n",
      "specificity = 0.7243986011515773\n",
      "opt_score = 0.45135039937507443\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "#net.load_state_dict(best_state_dict)\n",
    "dmodel.eval()\n",
    "output = dmodel(X_test_tensor).to(\"cpu\")\n",
    "result = predicts(output)\n",
    "y_test = imb[\"y_test\"]\n",
    "plt_title = 'Payment with Difficulties'\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confmat = confusion_matrix(y_true=y_test, y_pred=result)\n",
    "fig, ax = plt.subplots(figsize=(3, 3))\n",
    "ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(confmat.shape[0]):\n",
    "    for j in range(confmat.shape[1]):\n",
    "        ax.text(x=j, y=i, s=confmat[i, j], va='center', ha='center')\n",
    "\n",
    "plt.xticks([0, 1], [0, 1])\n",
    "plt.yticks([0, 1], [0, 1])\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.ylabel('Actual Class')\n",
    "plt.title(plt_title)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('under_sampling_confusion_matrix.png', transparent = True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "acc = accuracy_score(y_test, result)\n",
    "f1 = f1_score(y_test, result)\n",
    "precision = precision_score(y_test, result)\n",
    "recall = recall_score(y_test, result)\n",
    "spe = specificity_score(y_test, result)\n",
    "opt = opt_score(y_test, result)\n",
    "print('accuracy =', acc)\n",
    "print('f1_score =', f1)\n",
    "print('precision =', precision)\n",
    "print('recall =', recall)\n",
    "print('specificity =', spe)\n",
    "print('opt_score =', opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y6Aitbbzgtxy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DNNfinal.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
